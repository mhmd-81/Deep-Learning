{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Greedy search using Skorch","metadata":{}},{"cell_type":"code","source":"!pip install skorch\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom skorch import NeuralNetRegressor\nfrom sklearn.model_selection import GridSearchCV\nfrom datetime import datetime\nfrom collections import defaultdict","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Load dataset","metadata":{}},{"cell_type":"code","source":"# Load and preprocess the data\ndf = pd.read_csv(\"you'r dataset\")\nuser_logins = df['column_1'].value_counts()\nprint('Number of total users:', len(user_logins))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Preprocessing","metadata":{}},{"cell_type":"code","source":"# Filter data for users with more than 50 logins\nfiltered_user_logins = user_logins[user_logins > 50]\ndf_user_logins_gt50 = df[df['column_1'].isin(filtered_user_logins.index)].copy()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Add time features\ndf_user_logins_gt50['timestamp'] = pd.to_datetime(df_user_logins_gt50['time'])\ndf_user_logins_gt50['date'] = df_user_logins_gt50['timestamp'].dt.date\ndf_user_logins_gt50['hour'] = df_user_logins_gt50['timestamp'].dt.hour","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create hourly login vectors\nuser_hour = df_user_logins_gt50.groupby(['column_1', 'hour']).size().unstack(fill_value=0)\nuser_vectors = user_hour.to_numpy()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define time range for login vector processing\nstart_time = datetime.strptime(\"2024-01-17 12:00:31\", \"%Y-%m-%d %H:%M:%S\")\nend_time = datetime.strptime(\"2024-07-05 11:57:40\", \"%Y-%m-%d %H:%M:%S\")\ntotal_hours = int((end_time - start_time).total_seconds() // 3600) + 1","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Generate login vectors\nuser_login_vectors = defaultdict(lambda: np.zeros(total_hours, dtype=int))\nfor _, row in df.iterrows():\n    username = row[\"column_1\"]  # Adjust based on actual column name\n    device_time = row[\"time\"]\n    login_time = datetime.strptime(device_time, \"%Y-%m-%d %H:%M:%S\")\n    if start_time <= login_time <= end_time:\n        hour_index = int((login_time - start_time).total_seconds() // 3600)\n        user_login_vectors[username][hour_index] += 1","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Convert login vectors to DataFrame\nlogin_data = {\n    \"username\": [],\n    \"logins\": []  # Column to hold login counts as lists\n}\n# Populate the DataFrame dictionary\nfor username, login_vector in user_login_vectors.items():\n    login_data[\"username\"].append(username)\n    login_data[\"logins\"].append(login_vector.tolist())  # Convert the numpy array to a list","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create the DataFrame\ndf_login_vectors = pd.DataFrame(login_data)\n\n# Choose a sample user\nsample = np.array(df_login_vectors.iloc[3, 1])\nprint(sample)\n# train-test split for time series\ntrain_size = int(len(sample) * 0.8)\ntest_size = len(sample) - train_size\ntrain, test = sample[:train_size].reshape((-1, 1)), sample[train_size:].reshape((-1, 1))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define a function to create datasets for LSTM\ndef create_dataset(dataset, lookback):\n    X, y = [], []\n    for i in range(len(dataset) - lookback):\n        feature = dataset[i:i + lookback]\n        target = dataset[i + lookback]\n        X.append(feature)\n        y.append(target)\n    return torch.tensor(X, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)\n\nlookback = 24\nX_train, y_train = create_dataset(train, lookback=lookback)\nX_test, y_test = create_dataset(test, lookback=lookback)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### LSTM model ","metadata":{}},{"cell_type":"code","source":"# Define the LSTM model\nclass LoginModel(nn.Module):\n    def __init__(self, hidden_size=20):\n        super().__init__()\n        self.lstm = nn.LSTM(input_size=1, hidden_size=hidden_size, num_layers=1, batch_first=True)\n        self.linear = nn.Linear(hidden_size, 1)\n\n    # In your model's forward function\n    def forward(self, x):\n        x, _ = self.lstm(x)\n        x = x[:, -1, :]\n        x = self.linear(x)\n        return x","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Greedy search function","metadata":{}},{"cell_type":"code","source":"# Initialize Skorch NeuralNetRegressor\n# Create model with skorch\nmodel = NeuralNetRegressor(\n  module=LoginModel,\n  criterion=nn.MSELoss(),\n  verbose=False\n)\n\n# Define the grid search parameters\nparam_grid = {\n    'optimizer': [optim.SGD, optim.Adam, optim.Adagrad],\n    'optimizer__lr': [0.001, 0.0001],\n    'module__hidden_size': [12, 24, 36, 48, 60, 72],\n    'batch_size': [128, 256, 512],\n    'max_epochs': [2000, 3000, 4000]\n}\n\ngrid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\ngrid_result = grid.fit(X_train, y_train)\n\n# Summarize results\nprint(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\nmeans = grid_result.cv_results_['mean_test_score']\nstds = grid_result.cv_results_['std_test_score']\nparams = grid_result.cv_results_['params']\nfor mean, stdev, param in zip(means, stds, params):\n    print(\"%f (%f) with: %r\" % (mean, stdev, param))","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}